{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d576ab8-29a5-4a75-8dda-38bddbd648f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le modèle SVM a été entraîné.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from skimage import io, color\n",
    "from skimage.feature import hog\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "def load_images_and_labels(image_dir, label_dir):\n",
    "    data = []\n",
    "    labels = []\n",
    "    columns = ['x1', 'y1', 'x2', 'y2', 'label']\n",
    "\n",
    "    for filename in os.listdir(image_dir):\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            image_path = os.path.join(image_dir, filename)\n",
    "            csv_path = os.path.join(label_dir, filename[:-4] + \".csv\")\n",
    "            \n",
    "            if not os.path.exists(csv_path):\n",
    "                continue\n",
    "\n",
    "            image = io.imread(image_path)\n",
    "            if len(image.shape) > 2:\n",
    "                image = color.rgb2gray(image)  # Convertir en niveaux de gris pour HOG\n",
    "\n",
    "            df = pd.read_csv(csv_path, header=None, names=columns)\n",
    "            for _, row in df.iterrows():\n",
    "                label = row['label'].strip()\n",
    "                if label == 'ff':\n",
    "                    continue  # Ignorer les labels 'ff'\n",
    "                \n",
    "                if label == 'empty':\n",
    "                    # Diviser l'image en 9 sous-images et utiliser chaque sous-image pour les cas 'empty'\n",
    "                    height, width = image.shape\n",
    "                    sub_images = [\n",
    "                        image[:height//3, :width//3],\n",
    "                        image[:height//3, width//3:2*width//3],\n",
    "                        image[:height//3, 2*width//3:],\n",
    "                        image[height//3:2*height//3, :width//3],\n",
    "                        image[height//3:2*height//3, 2*width//3:],\n",
    "                        image[2*height//3:, :width//3],\n",
    "                    ]\n",
    "                    for sub_image in sub_images:\n",
    "                        sub_image_resized = Image.fromarray(sub_image).resize((100, 100))\n",
    "                        hog_features = hog(np.array(sub_image_resized),orientations=16, pixels_per_cell=(8, 8),\n",
    "                                           cells_per_block=(2, 2), visualize=False, feature_vector=True)\n",
    "                        data.append(hog_features)\n",
    "                        labels.append(label)  # Utiliser le label 'empty' pour chaque sous-image\n",
    "                else:\n",
    "                    x1, y1, x2, y2 = int(row['x1']), int(row['y1']), int(row['x2']), int(row['y2'])\n",
    "                    if x1 >= x2 or y1 >= y2 or x1 < 0 or y1 < 0 or x2 > image.shape[1] or y2 > image.shape[0]:\n",
    "                        continue\n",
    "                    roi = image[y1:y2, x1:x2]\n",
    "                    if roi.size == 0:\n",
    "                        continue\n",
    "                    roi_resized = Image.fromarray(roi).resize((100, 100))  # S'assurer que le redimensionnement est correct\n",
    "                    roi_array = np.array(roi_resized)\n",
    "                    hog_features = hog(roi_array,orientations=16, pixels_per_cell=(8, 8),\n",
    "                                           cells_per_block=(2, 2), visualize=False, feature_vector=True)\n",
    "                    data.append(hog_features)\n",
    "                    labels.append(label)  # Utiliser le label spécifique du panneau\n",
    "\n",
    "    return np.array(data, dtype='float64'), np.array(labels)  # Les labels seront convertis séparément\n",
    "\n",
    "# Chemins vers les dossiers d'images et de labels\n",
    "image_dir = 'train/images2'\n",
    "label_dir = 'train/labels2'\n",
    "\n",
    "# Charger les données\n",
    "features, target = load_images_and_labels(image_dir, label_dir)\n",
    "\n",
    "# Encoder les labels\n",
    "label_encoder = LabelEncoder()\n",
    "target_encoded = label_encoder.fit_transform(target)\n",
    "\n",
    "# Création et entraînement du SVM avec probability=True\n",
    "clf = svm.SVC(kernel='linear', probability=True)\n",
    "clf.fit(features, target_encoded)  # Utiliser les labels encodés\n",
    "print(\"Le modèle SVM a été entraîné.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa04442-0653-4259-b689-9140b3ece2f5",
   "metadata": {},
   "source": [
    "## Détection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d543487-696e-421e-8aad-33da0602d89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_and_display_shapes(image_path, clf, label_encoder, confidence_threshold=0.4):\n",
    "    # Charger l'image\n",
    "    image = io.imread(image_path)\n",
    "    image_pil = Image.fromarray(image)\n",
    "    image_gray = color.rgb2gray(image)\n",
    "\n",
    "    # Appliquer un seuillage pour binariser l'image\n",
    "    thresh = filters.threshold_otsu(image_gray)\n",
    "    bw = morphology.closing(image_gray > thresh, morphology.square(3))\n",
    "\n",
    "    # Enlever les objets connectés au bord de l'image\n",
    "    cleared = morphology.remove_small_objects(bw, 20)\n",
    "    cleared = morphology.remove_small_holes(cleared, 20)\n",
    "\n",
    "    # Utiliser la détection de contours pour améliorer la détection des formes\n",
    "    edges = feature.canny(image_gray, sigma=2.0)\n",
    "    filled_edges = morphology.binary_closing(edges, morphology.square(3))\n",
    "    label_image = measure.label(filled_edges)\n",
    "\n",
    "    # Détecter les propriétés des régions\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.imshow(image)\n",
    "\n",
    "    all_detections = []\n",
    "\n",
    "    for region in measure.regionprops(label_image):\n",
    "        # Sauter les petites régions\n",
    "        if region.area < 100:\n",
    "            continue\n",
    "\n",
    "        # Détecter la boîte englobante\n",
    "        minr, minc, maxr, maxc = region.bbox\n",
    "\n",
    "        # Préparer les données pour la classification\n",
    "        box = (minc, minr, maxc, maxr)\n",
    "        hog_features = prepare_data(image_pil, box)\n",
    "        probabilities = clf.predict_proba([hog_features])[0]\n",
    "        max_proba = np.max(probabilities)\n",
    "\n",
    "        if max_proba >= confidence_threshold:\n",
    "            prediction = np.argmax(probabilities)\n",
    "            predicted_label = label_encoder.inverse_transform([prediction])[0]\n",
    "            if predicted_label != 'empty':\n",
    "                all_detections.append((max_proba, predicted_label, minc, minr, maxc, maxr))\n",
    "\n",
    "    # Détection avec fenêtres 64x128\n",
    "    for region in measure.regionprops(label_image):\n",
    "        # Sauter les petites régions\n",
    "        if region.area < 100:\n",
    "            continue\n",
    "\n",
    "        # Détecter la boîte englobante\n",
    "        minr, minc, maxr, maxc = region.bbox\n",
    "        height = maxr - minr\n",
    "        width = maxc - minc\n",
    "\n",
    "        if height != 128 or width != 64:\n",
    "            continue\n",
    "\n",
    "        # Préparer les données pour la classification\n",
    "        box = (minc, minr, maxc, maxr)\n",
    "        hog_features = prepare_data(image_pil, box)\n",
    "        probabilities = clf.predict_proba([hog_features])[0]\n",
    "        max_proba = np.max(probabilities)\n",
    "\n",
    "        if max_proba >= confidence_threshold:\n",
    "            prediction = np.argmax(probabilities)\n",
    "            predicted_label = label_encoder.inverse_transform([prediction])[0]\n",
    "            if predicted_label in ['frouge', 'fvert', 'forange']:\n",
    "                all_detections.append((max_proba, predicted_label, minc, minr, maxc, maxr))\n",
    "\n",
    "    # Filtrer les boîtes englobantes qui sont complètement contenues dans d'autres\n",
    "    filtered_detections = []\n",
    "    for i, det1 in enumerate(all_detections):\n",
    "        contained = False\n",
    "        for j, det2 in enumerate(all_detections):\n",
    "            if i != j and is_contained(det1[2:], det2[2:]):\n",
    "                contained = True\n",
    "                if det1[0] > det2[0]:  # Si la boîte intérieure a une meilleure précision, remplacer\n",
    "                    if det2 in filtered_detections:\n",
    "                        filtered_detections.remove(det2)\n",
    "                    filtered_detections.append(det1)\n",
    "                break\n",
    "        if not contained:\n",
    "            filtered_detections.append(det1)\n",
    "\n",
    "    # Sélectionner une seule boîte parmi les boîtes proches\n",
    "    selected_detections = []\n",
    "    while filtered_detections:\n",
    "        det = filtered_detections.pop(0)\n",
    "        proba, label, minc, minr, maxc, maxr = det\n",
    "        close_detections = [d for d in filtered_detections if is_close(d, det)]\n",
    "        for close_det in close_detections:\n",
    "            if close_det in filtered_detections:\n",
    "                filtered_detections.remove(close_det)\n",
    "            if close_det[0] > proba:\n",
    "                det = close_det\n",
    "        selected_detections.append(det)\n",
    "\n",
    "    ax.set_axis_off()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Préparer les résultats avec les pourcentages de confiance les plus élevés\n",
    "    detections_summary = {}\n",
    "    for detection in selected_detections:\n",
    "        proba, label, x1, y1, x2, y2 = detection\n",
    "        if label not in detections_summary or proba > detections_summary[label]:\n",
    "            detections_summary[label] = proba\n",
    "\n",
    "    # Trier les détections par confiance décroissante\n",
    "    sorted_detections = sorted(detections_summary.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Afficher le panneau avec le pourcentage le plus élevé\n",
    "    if sorted_detections:\n",
    "        best_label, best_proba = sorted_detections[0]\n",
    "        result_phrase = f\"Cette image contient à priori ce panneau : {best_label} à {best_proba * 100:.2f}%\"\n",
    "    else:\n",
    "        result_phrase = \"Aucun panneau détecté avec une confiance suffisante.\"\n",
    "\n",
    "   # print(result_phrase)\n",
    "    return result_phrase, selected_detections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fd2d67c4-6ec7-4c8f-938b-cc2155ace888",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "from skimage.transform import pyramid_gaussian\n",
    "from collections import defaultdict\n",
    "from joblib import Parallel, delayed\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, color, measure, filters, morphology, feature\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Fonction pour préparer les données HOG avec les coordonnées\n",
    "def prepare_data(image, box):\n",
    "    x1, y1, x2, y2 = box\n",
    "    patch = image.crop((x1, y1, x2, y2))\n",
    "    patch_resized = patch.resize((100, 100))  # Redimensionner à 100x100 pour correspondre au modèle entraîné\n",
    "    patch_array = np.array(patch_resized)\n",
    "    # Convertir l'image en niveaux de gris si elle est en couleur\n",
    "    if patch_array.ndim == 3:\n",
    "        patch_array = np.mean(patch_array, axis=2)\n",
    "    hog_features = hog(patch_array, orientations=16, pixels_per_cell=(8, 8),\n",
    "                       cells_per_block=(2, 2), visualize=False, feature_vector=True)\n",
    "    return hog_features\n",
    "\n",
    "# Fonction pour faire glisser la fenêtre\n",
    "def sliding_window(image, step_size, window_size):\n",
    "    for y in range(0, image.height - window_size[1] + 1, step_size):\n",
    "        for x in range(0, image.width - window_size[0] + 1, step_size):\n",
    "            yield (x, y, x + window_size[0], y + window_size[1])\n",
    "def detect_with_fixed_window(image, win_size, step_size, confidence_threshold, clf, label_encoder):\n",
    "    detections = []\n",
    "    for (i, resized) in enumerate(pyramid_gaussian(np.array(image), downscale=1.5, max_layer=4)):\n",
    "        resized_image = Image.fromarray((resized * 255).astype(np.uint8))\n",
    "        boxes = list(sliding_window(resized_image, step_size, win_size))\n",
    "        results = Parallel(n_jobs=-1)(delayed(detect_single_window)(resized_image, box, clf, label_encoder, confidence_threshold) for box in boxes)\n",
    "        results = [r for r in results if r is not None]\n",
    "\n",
    "        for max_proba, predicted_label, (x1, y1, x2, y2) in results:\n",
    "            # Ajuster les coordonnées à l'échelle originale\n",
    "            scale_factor = 1.5 ** i\n",
    "            original_x1 = int(x1 * scale_factor)\n",
    "            original_y1 = int(y1 * scale_factor)\n",
    "            original_x2 = int(x2 * scale_factor)\n",
    "            original_y2 = int(y2 * scale_factor)\n",
    "\n",
    "            # Stocker la détection\n",
    "            detections.append((max_proba, predicted_label, original_x1, original_y1, original_x2, original_y2))\n",
    "    \n",
    "    return detections\n",
    "def does_box_enclose(box1, box2):\n",
    "    x1_1, y1_1, x2_1, y2_1 = box1\n",
    "    x1_2, y1_2, x2_2, y2_2 = box2\n",
    "    return x1_1 <= x1_2 and y1_1 <= y1_2 and x2_1 >= x2_2 and y2_1 >= y2_2\n",
    "\n",
    "# Fonction pour vérifier si une boîte englobante en englobe une autre\n",
    "def does_box_enclose(box1, box2):\n",
    "    x1_1, y1_1, x2_1, y2_1 = box1\n",
    "    x1_2, y1_2, x2_2, y2_2 = box2\n",
    "    return x1_1 <= x1_2 and y1_1 <= y1_2 and x2_1 >= x2_2 and y2_1 >= y2_2\n",
    "\n",
    "# Fonction pour vérifier si deux boîtes englobantes sont trop proches\n",
    "def are_boxes_too_close(box1, box2, threshold=10):\n",
    "    x1_1, y1_1, x2_1, y2_1 = box1\n",
    "    x1_2, y1_2, x2_2, y2_2 = box2\n",
    "    return abs(x1_1 - x1_2) < threshold and abs(y1_1 - y1_2) < threshold and \\\n",
    "           abs(x2_1 - x2_2) < threshold and abs(y2_1 - y2_2) < threshold\n",
    "def filter_traffic_lights(detections, max_lights=2, proximity_threshold=50, confidence_threshold=0.75):\n",
    "    \"\"\"\n",
    "    Filtrer les détections de feux de signalisation pour conserver un maximum de `max_lights` détections,\n",
    "    avec une confiance supérieure à `confidence_threshold`, en évitant les doublons basés sur la proximité.\n",
    "    \"\"\"\n",
    "    # Filtrer les détections de feux de signalisation avec une confiance supérieure à confidence_threshold\n",
    "    traffic_light_detections = [det for det in detections if det[1] in ['frouge', 'fvert', 'forange'] and det[0] >= confidence_threshold]\n",
    "    \n",
    "    # Si aucun feu n'est détecté, retourner une liste vide\n",
    "    if not traffic_light_detections:\n",
    "        return []\n",
    "    \n",
    "    # Trier par confiance décroissante\n",
    "    traffic_light_detections = sorted(traffic_light_detections, key=lambda x: x[0], reverse=True)\n",
    "    \n",
    "    # Sélectionner les meilleurs feux en fonction de la proximité\n",
    "    selected_lights = []\n",
    "    while traffic_light_detections and len(selected_lights) < max_lights:\n",
    "        best_light = traffic_light_detections.pop(0)\n",
    "        selected_lights.append(best_light)\n",
    "        traffic_light_detections = [det for det in traffic_light_detections if not is_close(det, best_light, threshold=proximity_threshold)]\n",
    "    \n",
    "    return selected_lights\n",
    "\n",
    "def is_close(bbox1, bbox2, threshold=50):\n",
    "    \"\"\"\n",
    "    Vérifier si deux boîtes englobantes sont trop proches l'une de l'autre\n",
    "    \"\"\"\n",
    "    _, _, x1_1, y1_1, x2_1, y2_1 = bbox1\n",
    "    _, _, x1_2, y1_2, x2_2, y2_2 = bbox2\n",
    "    return (abs(x1_1 - x1_2) < threshold and abs(y1_1 - y1_2) < threshold and\n",
    "            abs(x2_1 - x2_2) < threshold and abs(y2_1 - y2_2) < threshold)\n",
    "\n",
    "def detect_signs_in_image(image_path, clf, label_encoder, confidence_threshold=0.4):\n",
    "    try:\n",
    "        # Charger l'image\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "        # Détection avec des carrés 64x64\n",
    "        detections_64x64 = detect_with_fixed_window(image, (64, 64), 64, confidence_threshold, clf, label_encoder)\n",
    "\n",
    "        # Détection avec des fenêtres 64x128\n",
    "        detections_64x128 = detect_with_fixed_window(image, (64, 128), 64, confidence_threshold, clf, label_encoder)\n",
    "\n",
    "        # Stocker les résultats\n",
    "        all_detections = detections_64x64 + detections_64x128\n",
    "\n",
    "        # Filtrer les boîtes englobantes et conserver celles avec la meilleure précision\n",
    "        all_detections = filter_enclosing_boxes(all_detections)\n",
    "\n",
    "        bboxes = []\n",
    "        bboxes_confidences = defaultdict(list)\n",
    "\n",
    "        for max_proba, predicted_label, x1, y1, x2, y2 in all_detections:\n",
    "            bboxes.append(((x1, y1, x2, y2), predicted_label))\n",
    "            bboxes_confidences[(x1, y1, x2, y2)].append(max_proba)\n",
    "\n",
    "        # Filtrer les détections avec une confiance supérieure à 65%\n",
    "        filtered_bboxes = [(bbox, label) for bbox, label in bboxes if max(bboxes_confidences[bbox]) >= 0.65]\n",
    "\n",
    "        # Filtrer les détections conflictuelles pour les feux de signalisation\n",
    "        final_bboxes = []\n",
    "        traffic_light_detections = []\n",
    "        for bbox, label in filtered_bboxes:\n",
    "            if label in ['frouge', 'forange', 'fvert']:\n",
    "                traffic_light_detections.append((max(bboxes_confidences[bbox]), label, bbox[0], bbox[1], bbox[2], bbox[3]))\n",
    "            else:\n",
    "                final_bboxes.append((bbox, label))\n",
    "        \n",
    "\n",
    "        # Limiter les détections de feux de signalisation à 2 et filtrer par proximité\n",
    "        selected_traffic_lights = filter_traffic_lights(traffic_light_detections, max_lights=2, confidence_threshold=0.75)\n",
    "        final_bboxes.extend([(det[2:], det[1]) for det in selected_traffic_lights])\n",
    "\n",
    "        # Éliminer les boîtes englobantes trop proches ou englobées\n",
    "        final_bboxes_filtered = []\n",
    "\n",
    "        for bbox, label in final_bboxes:\n",
    "            if not any(does_box_enclose(existing_bbox, bbox) or does_box_enclose(bbox, existing_bbox) for existing_bbox, existing_label in final_bboxes_filtered if existing_label == label):\n",
    "                final_bboxes_filtered.append((bbox, label))\n",
    "            else:\n",
    "                # Trouver et comparer les confiances\n",
    "                for i, (existing_bbox, existing_label) in enumerate(final_bboxes_filtered):\n",
    "                    if existing_label == label and (does_box_enclose(existing_bbox, bbox) or does_box_enclose(bbox, existing_bbox)):\n",
    "                        if max(bboxes_confidences[bbox]) > max(bboxes_confidences[existing_bbox]):\n",
    "                            final_bboxes_filtered[i] = (bbox, label)\n",
    "                        break\n",
    "        \n",
    "        final_bboxes = final_bboxes_filtered\n",
    "\n",
    "        # Trouver la boîte avec la plus grande valeur de prédiction\n",
    "        if final_bboxes:\n",
    "            best_bbox = max(bboxes_confidences.items(), key=lambda item: max(item[1]))\n",
    "            best_label = [label for bbox, label in final_bboxes if bbox == best_bbox[0]][0]\n",
    "            result_phrase = f\"L'image contient à priori le panneau {best_label} avec la plus grande valeur de confiance ({max(best_bbox[1]):.2f}).\"\n",
    "        else:\n",
    "            result_phrase = \"Aucun panneau détecté avec une confiance suffisante.\"\n",
    "\n",
    "        predicted_signs = list(set([label for _, label in final_bboxes]))\n",
    "\n",
    "        return predicted_signs, final_bboxes, bboxes_confidences, result_phrase\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur dans detect_signs_in_image: {e}\")\n",
    "        return [], [], defaultdict(list), \"La détection a échoué.\"\n",
    "\n",
    "\n",
    "def generate_result_phrases(final_bboxes, bboxes_confidences):\n",
    "    result_phrases = []\n",
    "    for bbox, label in final_bboxes:\n",
    "        confidences = bboxes_confidences[bbox]\n",
    "        max_confidence = max(confidences) * 100  # Convertir en pourcentage\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        phrase = f\"Panneau: {label}, Confiance: {max_confidence:.2f}%, Coordonnées: ({x1}, {y1}), ({x2}, {y2})\"\n",
    "        result_phrases.append(phrase)\n",
    "    return result_phrases\n",
    "def is_contained(inner_box, outer_box):\n",
    "    ix1, iy1, ix2, iy2 = inner_box\n",
    "    ox1, oy1, ox2, oy2 = outer_box\n",
    "    return ix1 >= ox1 and iy1 >= oy1 and ix2 <= ox2 and iy2 <= oy2\n",
    "\n",
    "\n",
    "def get_detected_sign_bounding_boxes(detections, threshold=0.89):\n",
    "    bounding_boxes = []\n",
    "    for detection in detections:\n",
    "        proba, label, x1, y1, x2, y2 = detection\n",
    "        if proba > threshold:\n",
    "            bounding_boxes.append((label, x1, y1, x2, y2, proba))\n",
    "    return bounding_boxes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f6ce6766-978d-4f9f-9bef-c4185d2e292d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_enclosing_boxes(detections):\n",
    "    \"\"\"\n",
    "    Filtrer les boîtes englobantes et conserver celles avec la meilleure précision.\n",
    "    \"\"\"\n",
    "    filtered_detections = []\n",
    "    for i, (proba1, label1, x1_1, y1_1, x2_1, y2_1) in enumerate(detections):\n",
    "        is_enclosed = False\n",
    "        for j, (proba2, label2, x1_2, y1_2, x2_2, y2_2) in enumerate(detections):\n",
    "            if i != j and does_box_enclose((x1_2, y1_2, x2_2, y2_2), (x1_1, y1_1, x2_1, y2_1)):\n",
    "                if proba2 >= proba1:\n",
    "                    is_enclosed = True\n",
    "                    break\n",
    "        if not is_enclosed:\n",
    "            filtered_detections.append((proba1, label1, x1_1, y1_1, x2_1, y2_1))\n",
    "    return filtered_detections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "00b63e70-1913-4708-a4e0-bb17769c5c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prédictions filtrées :\n",
      "('interdiction', 97.84, [(420, 6), (433, 23)])\n",
      "('fvert', 78.08, [(0, 288), (96, 480)])\n",
      "('danger', 77.81, [(64, 320), (128, 448)])\n",
      "Annotations chargées :\n",
      "    x1   y1   x2   y2         label\n",
      "0  710  365  754  404  interdiction\n",
      "1  707  303  744  365         fvert\n",
      "2  280  476  302  498  interdiction\n",
      "3  378  476  399  496  interdiction\n",
      "Correspondances trouvées :\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def detect_single_window(image, box, clf, label_encoder, confidence_threshold):\n",
    "    hog_features = prepare_data(image, box)\n",
    "    probabilities = clf.predict_proba([hog_features])[0]\n",
    "    max_proba = np.max(probabilities)\n",
    "    if max_proba >= confidence_threshold:\n",
    "        prediction = np.argmax(probabilities)\n",
    "        predicted_label = label_encoder.inverse_transform([prediction])[0]\n",
    "        if predicted_label != 'empty':\n",
    "            return max_proba, predicted_label, box\n",
    "    return None\n",
    "\n",
    "\n",
    "def compare_predictions_with_annotations(predictions, annotations):\n",
    "    matches = []\n",
    "    for pred in predictions:\n",
    "        label_pred, conf, coords = pred\n",
    "        x1_pred, y1_pred = coords[0]\n",
    "        x2_pred, y2_pred = coords[1]\n",
    "\n",
    "        for index, row in annotations.iterrows():\n",
    "            x1_true, y1_true, x2_true, y2_true, label_true = row\n",
    "\n",
    "            if label_pred == label_true:\n",
    "                x1_error = abs(x1_pred - x1_true) / x1_true\n",
    "                y1_error = abs(y1_pred - y1_true) / y1_true\n",
    "                x2_error = abs(x2_pred - x2_true) / x2_true\n",
    "                y2_error = abs(y2_pred - y2_true) / y2_true\n",
    "\n",
    "                if x1_error <= 0.5 and y1_error <= 0.5 and x2_error <= 0.5 and y2_error <= 0.5:\n",
    "                    matches.append((label_pred, conf, coords))\n",
    "    return matches\n",
    "def generate_result_phrases(final_bboxes, bboxes_confidences):\n",
    "    result_phrases = []\n",
    "    for bbox, label in final_bboxes:\n",
    "        confidences = bboxes_confidences[bbox]\n",
    "        max_confidence = max(confidences) * 100  # Convertir en pourcentage\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        phrase = f\"Panneau: {label}, Confiance: {max_confidence:.2f}%, Coordonnées: ({x1}, {y1}), ({x2}, {y2})\"\n",
    "        result_phrases.append(phrase)\n",
    "    return result_phrases\n",
    "\n",
    "def detect_and_display_shapes(image_path, clf, label_encoder, confidence_threshold=0.4):\n",
    "    image = io.imread(image_path)\n",
    "    image_gray = color.rgb2gray(image)\n",
    "    thresh = filters.threshold_otsu(image_gray)\n",
    "    bw = morphology.closing(image_gray > thresh, morphology.square(3))\n",
    "    cleared = morphology.remove_small_objects(bw, 20)\n",
    "    cleared = morphology.remove_small_holes(cleared, 20)\n",
    "    edges = feature.canny(image_gray, sigma=2.0)\n",
    "    filled_edges = morphology.binary_closing(edges, morphology.square(3))\n",
    "    label_image = measure.label(filled_edges)\n",
    "\n",
    "    all_detections = []\n",
    "\n",
    "    for region in measure.regionprops(label_image):\n",
    "        if region.area < 100:\n",
    "            continue\n",
    "\n",
    "        minr, minc, maxr, maxc = region.bbox\n",
    "        box = (minc, minr, maxc, maxr)\n",
    "        hog_features = prepare_data(Image.fromarray(image), box)\n",
    "        probabilities = clf.predict_proba([hog_features])[0]\n",
    "        max_proba = np.max(probabilities)\n",
    "\n",
    "        if max_proba >= confidence_threshold:\n",
    "            prediction = np.argmax(probabilities)\n",
    "            predicted_label = label_encoder.inverse_transform([prediction])[0]\n",
    "            if predicted_label != 'empty':\n",
    "                all_detections.append((max_proba, predicted_label, minc, minr, maxc, maxr))\n",
    "\n",
    "    filtered_detections = []\n",
    "    for i, det1 in enumerate(all_detections):\n",
    "        contained = False\n",
    "        for j, det2 in enumerate(all_detections):\n",
    "            if i != j and is_contained(det1[2:], det2[2:]):\n",
    "                contained = True\n",
    "                if det1[0] > det2[0]:\n",
    "                    if det2 in filtered_detections:\n",
    "                        filtered_detections.remove(det2)\n",
    "                    filtered_detections.append(det1)\n",
    "                break\n",
    "        if not contained:\n",
    "            filtered_detections.append(det1)\n",
    "\n",
    "    selected_detections = []\n",
    "    while filtered_detections:\n",
    "        det = filtered_detections.pop(0)\n",
    "        close_detections = [d for d in filtered_detections if (abs(d[2] - det[2]) < 20 and abs(d[3] - det[3]) < 20) or (abs(d[4] - det[4]) < 20 and abs(d[5] - det[5]) < 20)]\n",
    "        for close_det in close_detections:\n",
    "            if close_det in filtered_detections:\n",
    "                filtered_detections.remove(close_det)\n",
    "            if close_det[0] > det[0]:\n",
    "                det = close_det\n",
    "        selected_detections.append(det)\n",
    "\n",
    "    detections_summary = {label: proba for proba, label, _, _, _, _ in selected_detections}\n",
    "    sorted_detections = sorted(detections_summary.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    result_phrase = f\"Cette image contient à priori ce panneau : {sorted_detections[0][0]} à {sorted_detections[0][1] * 100:.2f}%\" if sorted_detections else \"Aucun panneau détecté avec une confiance suffisante.\"\n",
    "    \n",
    "    return result_phrase, selected_detections\n",
    "\n",
    "def load_csv_annotations(csv_path):\n",
    "    df = pd.read_csv(csv_path, header=None)\n",
    "    df.columns = ['x1', 'y1', 'x2', 'y2', 'label']\n",
    "    return df\n",
    "\n",
    "def parse_prediction(prediction):\n",
    "    panneau = re.search(r'Panneau: (\\w+)', prediction).group(1)\n",
    "    confiance = float(re.search(r'Confiance: ([\\d.]+)%', prediction).group(1))\n",
    "    coordonnees = re.findall(r'\\((\\d+), (\\d+)\\)', prediction)\n",
    "    return (panneau, confiance, [(int(x), int(y)) for x, y in coordonnees])\n",
    "\n",
    "def cadre_englobant(cadre1, cadre2):\n",
    "    (x1_min, y1_min), (x1_max, y1_max) = cadre1\n",
    "    (x2_min, y2_min), (x2_max, y2_max) = cadre2\n",
    "    return x1_min <= x2_min and y1_min <= y2_min and x1_max >= x2_max and y1_max >= y2_max\n",
    "\n",
    "def filtrer_panneaux(panneaux):\n",
    "    panneaux = sorted(panneaux, key=lambda x: x[1], reverse=True)\n",
    "    result = []\n",
    "    for i, (type1, precision1, cadre1) in enumerate(panneaux):\n",
    "        if not any(i != j and cadre_englobant(cadre2, cadre1) for j, (type2, precision2, cadre2) in enumerate(panneaux)):\n",
    "            result.append((type1, precision1, cadre1))\n",
    "    return result\n",
    "\n",
    "\n",
    "def main(image_path, clf, label_encoder):\n",
    "    Total = []\n",
    "    predicted_signs, final_bboxes, bboxes_confidences, result_phrase = detect_signs_in_image(image_path, clf, label_encoder)\n",
    "    result_phrases = generate_result_phrases(final_bboxes, bboxes_confidences)\n",
    "    Total.extend(result_phrases)\n",
    "\n",
    "    result_phrase, detections = detect_and_display_shapes(image_path, clf, label_encoder)\n",
    "    bounding_boxes = get_detected_sign_bounding_boxes(detections)\n",
    "    filtered_bounding_boxes = bounding_boxes[:]\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(filtered_bounding_boxes):\n",
    "        bbox1 = filtered_bounding_boxes[i]\n",
    "        j = i + 1\n",
    "        while j < len(filtered_bounding_boxes):\n",
    "            bbox2 = filtered_bounding_boxes[j]\n",
    "            if is_close(bbox1, bbox2):\n",
    "                if bbox1[-1] >= bbox2[-1]:\n",
    "                    filtered_bounding_boxes.pop(j)\n",
    "                else:\n",
    "                    filtered_bounding_boxes.pop(i)\n",
    "                    i -= 1\n",
    "                    break\n",
    "            else:\n",
    "                j += 1\n",
    "        i += 1\n",
    "\n",
    "    for bbox in filtered_bounding_boxes:\n",
    "        label, x1, y1, x2, y2, proba = bbox\n",
    "        Total.append(f\"Panneau: {label}, Confiance: {proba*100:.2f}%, Coordonnées: ({x1}, {y1}), ({x2}, {y2})\")\n",
    "    \n",
    "    return Total\n",
    "\n",
    "# Chemin de l'image\n",
    "image_path = 'train/images/0003.jpg'\n",
    "# Assurez-vous que `clf` et `label_encoder` sont déjà entraînés et disponibles\n",
    "predictions = main(image_path, clf, label_encoder)\n",
    "\n",
    "# Parse predictions\n",
    "parsed_predictions = [parse_prediction(pred) for pred in predictions]\n",
    "\n",
    "# Filtrage des panneaux\n",
    "panneaux_filtrés = filtrer_panneaux(parsed_predictions)\n",
    "print(\"Prédictions filtrées :\")\n",
    "for i in panneaux_filtrés:\n",
    "    print(i)\n",
    "\n",
    "# Chemin du fichier CSV associé à l'image\n",
    "csv_path = 'train/labels/0003.csv'\n",
    "annotations = load_csv_annotations(csv_path)\n",
    "\n",
    "# Afficher les annotations chargées\n",
    "print(\"Annotations chargées :\")\n",
    "print(annotations)\n",
    "\n",
    "# Comparer les prédictions avec les annotations\n",
    "matches = compare_predictions_with_annotations(panneaux_filtrés, annotations)\n",
    "\n",
    "# Afficher les correspondances\n",
    "print(\"Correspondances trouvées :\")\n",
    "for match in matches:\n",
    "    print(match)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1041bfeb-6d2c-4350-a904-d7a0d21dffd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3965618f-e24a-40e5-9bb9-d832ff70a70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur dans detect_signs_in_image: list index out of range\n",
      "Total des annotations : 131\n",
      "Total des correspondances : 47\n",
      "Accuracy : 35.88%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def load_csv_annotations(csv_path):\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path, header=None)\n",
    "        if df.empty:\n",
    "            raise pd.errors.EmptyDataError\n",
    "        df.columns = ['x1', 'y1', 'x2', 'y2', 'label']\n",
    "        return df\n",
    "    except pd.errors.EmptyDataError:\n",
    "        return pd.DataFrame(columns=['x1', 'y1', 'x2', 'y2', 'label'])\n",
    "\n",
    "def calculate_iou(boxA, boxB):\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "\n",
    "    return iou\n",
    "\n",
    "def compare_predictions_with_annotations(predictions, annotations, iou_threshold=0.5):\n",
    "    matches = []\n",
    "    for pred in predictions:\n",
    "        label_pred, conf, coords = pred\n",
    "        x1_pred, y1_pred = coords[0]\n",
    "        x2_pred, y2_pred = coords[1]\n",
    "        pred_box = (x1_pred, y1_pred, x2_pred, y2_pred)\n",
    "\n",
    "        for index, row in annotations.iterrows():\n",
    "            x1_true, y1_true, x2_true, y2_true, label_true = row\n",
    "            true_box = (x1_true, y1_true, x2_true, y2_true)\n",
    "\n",
    "            if label_pred == label_true:\n",
    "                iou = calculate_iou(pred_box, true_box)\n",
    "\n",
    "                if iou >= iou_threshold:\n",
    "                    matches.append((label_pred, conf, coords))\n",
    "    return matches\n",
    "\n",
    "def calculate_accuracy(matches, total_annotations):\n",
    "    return len(matches) / total_annotations * 100 if total_annotations > 0 else 0\n",
    "\n",
    "def create_detection_csv(predictions, output_file):\n",
    "    with open(output_file, 'w') as f:\n",
    "        for pred in predictions:\n",
    "            label_pred, conf, coords, image_number = pred\n",
    "            x1_pred, y1_pred = coords[0]\n",
    "            x2_pred, y2_pred = coords[1]\n",
    "            f.write(f\"{image_number}, {x1_pred}, {y1_pred}, {x2_pred}, {y2_pred}, {conf}, {label_pred}\\n\")\n",
    "\n",
    "image_folder = 'val/images/'\n",
    "label_folder = 'val/labels/'\n",
    "\n",
    "all_predictions = []\n",
    "all_annotations = []\n",
    "all_matches = []\n",
    "\n",
    "for image_file in os.listdir(image_folder):\n",
    "    if image_file.endswith('.jpg'):\n",
    "        image_path = os.path.join(image_folder, image_file)\n",
    "        csv_file = image_file.replace('.jpg', '.csv')\n",
    "        csv_path = os.path.join(label_folder, csv_file)\n",
    "        \n",
    "        if not os.path.exists(csv_path):\n",
    "            continue\n",
    "\n",
    "        predictions = main(image_path, clf, label_encoder)\n",
    "        parsed_predictions = [parse_prediction(pred) for pred in predictions]\n",
    "        panneaux_filtrés = filtrer_panneaux(parsed_predictions)\n",
    "\n",
    "        annotations = load_csv_annotations(csv_path)\n",
    "\n",
    "        if annotations.empty:\n",
    "            continue\n",
    "\n",
    "        matches = compare_predictions_with_annotations(panneaux_filtrés, annotations)\n",
    "        \n",
    "        for pred in panneaux_filtrés:\n",
    "            pred_list = list(pred)\n",
    "            pred_list.append(image_file.replace('.jpg', ''))\n",
    "            all_predictions.append(pred_list)\n",
    "\n",
    "        all_annotations.extend(annotations.values.tolist())\n",
    "        all_matches.extend(matches)\n",
    "\n",
    "accuracy = calculate_accuracy(all_matches, len(all_annotations))\n",
    "\n",
    "print(f\"Total des annotations : {len(all_annotations)}\")\n",
    "print(f\"Total des correspondances : {len(all_matches)}\")\n",
    "print(f\"Accuracy : {accuracy:.2f}%\")\n",
    "\n",
    "create_detection_csv(all_predictions, 'detection.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
