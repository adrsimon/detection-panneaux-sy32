{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29b818c8-14cc-4d63-80d0-de9d3758514c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le modèle SVM a été entraîné.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from skimage import io, color\n",
    "from skimage.feature import hog\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "def load_images_and_labels(image_dir, label_dir):\n",
    "    data = []\n",
    "    labels = []\n",
    "    columns = ['x1', 'y1', 'x2', 'y2', 'label']\n",
    "\n",
    "    for filename in os.listdir(image_dir):\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            image_path = os.path.join(image_dir, filename)\n",
    "            csv_path = os.path.join(label_dir, filename[:-4] + \".csv\")\n",
    "            \n",
    "            if not os.path.exists(csv_path):\n",
    "                continue\n",
    "\n",
    "            image = io.imread(image_path)\n",
    "            if len(image.shape) > 2:\n",
    "                image = color.rgb2gray(image)  # Convertir en niveaux de gris pour HOG\n",
    "\n",
    "            df = pd.read_csv(csv_path, header=None, names=columns)\n",
    "            for _, row in df.iterrows():\n",
    "                label = row['label'].strip()\n",
    "                if label == 'ff':\n",
    "                    continue  # Ignorer les labels 'ff'\n",
    "                \n",
    "                if label == 'empty':\n",
    "                    # Diviser l'image en 9 sous-images et utiliser chaque sous-image pour les cas 'empty'\n",
    "                    height, width = image.shape\n",
    "                    sub_images = [\n",
    "                        image[:height//3, :width//3],\n",
    "                        image[:height//3, width//3:2*width//3],\n",
    "                        image[:height//3, 2*width//3:],\n",
    "                        image[height//3:2*height//3, :width//3],\n",
    "                        image[height//3:2*height//3, 2*width//3:],\n",
    "                        image[2*height//3:, :width//3],\n",
    "                    ]\n",
    "                    for sub_image in sub_images:\n",
    "                        sub_image_resized = Image.fromarray(sub_image).resize((100, 100))\n",
    "                        hog_features = hog(np.array(sub_image_resized),orientations=16, pixels_per_cell=(8, 8),\n",
    "                                           cells_per_block=(2, 2), visualize=False, feature_vector=True)\n",
    "                        data.append(hog_features)\n",
    "                        labels.append(label)  # Utiliser le label 'empty' pour chaque sous-image\n",
    "                else:\n",
    "                    x1, y1, x2, y2 = int(row['x1']), int(row['y1']), int(row['x2']), int(row['y2'])\n",
    "                    if x1 >= x2 or y1 >= y2 or x1 < 0 or y1 < 0 or x2 > image.shape[1] or y2 > image.shape[0]:\n",
    "                        continue\n",
    "                    roi = image[y1:y2, x1:x2]\n",
    "                    if roi.size == 0:\n",
    "                        continue\n",
    "                    roi_resized = Image.fromarray(roi).resize((100, 100))  # S'assurer que le redimensionnement est correct\n",
    "                    roi_array = np.array(roi_resized)\n",
    "                    hog_features = hog(roi_array,orientations=16, pixels_per_cell=(8, 8),\n",
    "                                           cells_per_block=(2, 2), visualize=False, feature_vector=True)\n",
    "                    data.append(hog_features)\n",
    "                    labels.append(label)  # Utiliser le label spécifique du panneau\n",
    "\n",
    "    return np.array(data, dtype='float64'), np.array(labels)  # Les labels seront convertis séparément\n",
    "\n",
    "# Chemins vers les dossiers d'images et de labels\n",
    "image_dir = 'train/images2'\n",
    "label_dir = 'train/labels2'\n",
    "\n",
    "# Charger les données\n",
    "features, target = load_images_and_labels(image_dir, label_dir)\n",
    "\n",
    "# Encoder les labels\n",
    "label_encoder = LabelEncoder()\n",
    "target_encoded = label_encoder.fit_transform(target)\n",
    "\n",
    "# Création et entraînement du SVM avec probability=True\n",
    "clf = svm.SVC(kernel='linear', probability=True)\n",
    "clf.fit(features, target_encoded)  # Utiliser les labels encodés\n",
    "print(\"Le modèle SVM a été entraîné.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b1a94cb-9e64-4024-97ac-3d2ff29745f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Signs:\n",
      "[{'label': 'danger', 'box': (71, 431, 167, 527), 'confidence': 0.9741884141635011}, {'label': 'danger', 'box': (576, 96, 640, 160), 'confidence': 0.9598329116298248}, {'label': 'danger', 'box': (144, 528, 208, 592), 'confidence': 0.9340446679503872}, {'label': 'danger', 'box': (215, 647, 311, 743), 'confidence': 0.9259103678261708}, {'label': 'danger', 'box': (0, 484, 323, 808), 'confidence': 0.8835659294366363}, {'label': 'interdiction', 'box': (288, 0, 352, 64), 'confidence': 0.8827871081884444}, {'label': 'danger', 'box': (215, 647, 359, 791), 'confidence': 0.8571996507437492}, {'label': 'ceder', 'box': (624, 144, 688, 208), 'confidence': 0.8488426503219609}, {'label': 'interdiction', 'box': (240, 48, 304, 112), 'confidence': 0.8417652978260273}, {'label': 'fvert', 'box': (215, 287, 311, 479), 'confidence': 0.831528780559842}, {'label': 'danger', 'box': (0, 864, 64, 928), 'confidence': 0.8249915206148462}, {'label': 'ceder', 'box': (480, 0, 544, 64), 'confidence': 0.8103517982863554}, {'label': 'interdiction', 'box': (431, 647, 527, 743), 'confidence': 0.8040981373715553}, {'label': 'ceder', 'box': (288, 768, 352, 832), 'confidence': 0.7863226946193611}, {'label': 'danger', 'box': (192, 240, 256, 304), 'confidence': 0.7682255041236722}, {'label': 'fvert', 'box': (359, 431, 455, 623), 'confidence': 0.7651048663961282}, {'label': 'fvert', 'box': (480, 720, 544, 848), 'confidence': 0.7461419773896981}, {'label': 'interdiction', 'box': (0, 647, 143, 791), 'confidence': 0.7401227579026801}, {'label': 'interdiction', 'box': (0, 215, 143, 359), 'confidence': 0.733749908589294}, {'label': 'ceder', 'box': (575, 791, 671, 887), 'confidence': 0.7258830594703051}, {'label': 'fvert', 'box': (503, 503, 599, 695), 'confidence': 0.707823426841579}, {'label': 'danger', 'box': (432, 240, 496, 304), 'confidence': 0.7077820410021517}, {'label': 'danger', 'box': (192, 624, 256, 688), 'confidence': 0.6975461661989841}, {'label': 'danger', 'box': (240, 720, 304, 784), 'confidence': 0.6685127161322939}, {'label': 'ceder', 'box': (575, 863, 671, 959), 'confidence': 0.6673368229324368}, {'label': 'fvert', 'box': (143, 0, 239, 191), 'confidence': 0.6631975812895604}]\n",
      "\n",
      "Real Labels:\n",
      "[{'box': (101, 385, 603, 796), 'label': 'ceder'}]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from skimage import io, color\n",
    "from skimage.feature import hog\n",
    "from skimage.transform import pyramid_gaussian\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def sliding_window(image, step_size, window_size):\n",
    "    for y in range(0, image.shape[0] - window_size[1], step_size):\n",
    "        for x in range(0, image.shape[1] - window_size[0], step_size):\n",
    "            yield (x, y, image[y:y + window_size[1], x:x + window_size[0]])\n",
    "\n",
    "def non_max_suppression(boxes, scores, labels, overlap_thresh=0.3):\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "\n",
    "    boxes = np.array(boxes)\n",
    "    scores = np.array(scores)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = boxes[:, 2]\n",
    "    y2 = boxes[:, 3]\n",
    "\n",
    "    areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    order = scores.argsort()[::-1]\n",
    "\n",
    "    keep = []\n",
    "    while order.size > 0:\n",
    "        i = order[0]\n",
    "        keep.append(i)\n",
    "\n",
    "        xx1 = np.maximum(x1[i], x1[order[1:]])\n",
    "        yy1 = np.maximum(y1[i], y1[order[1:]])\n",
    "        xx2 = np.minimum(x2[i], x2[order[1:]])\n",
    "        yy2 = np.minimum(y2[i], y2[order[1:]])\n",
    "\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "\n",
    "        inter = w * h\n",
    "        overlap = inter / (areas[i] + areas[order[1:]] - inter)\n",
    "\n",
    "        overlap_indices = np.where(overlap > overlap_thresh)[0] + 1\n",
    "\n",
    "        # Keep only the boxes with the highest score among those that overlap, considering labels and different scales\n",
    "        for j in overlap_indices:\n",
    "            if labels[order[j]] == labels[i] and scores[order[j]] < scores[i]:\n",
    "                order = np.delete(order, j)\n",
    "            elif labels[order[j]] == labels[i] and scores[order[j]] >= scores[i]:\n",
    "                order = np.delete(order, 0)\n",
    "                break\n",
    "\n",
    "        order = np.delete(order, 0)\n",
    "\n",
    "    return keep\n",
    "\n",
    "\n",
    "def process_window(window, x, y, scale, window_size, model, label_encoder, valid_labels, threshold):\n",
    "    if window.shape[0] != window_size[1] or window.shape[1] != window_size[0]:\n",
    "        return None\n",
    "\n",
    "    window_resized = Image.fromarray(window).resize((100, 100))\n",
    "    hog_features = hog(np.array(window_resized), orientations=16, pixels_per_cell=(8, 8),\n",
    "                       cells_per_block=(2, 2), visualize=False, feature_vector=True)\n",
    "\n",
    "    hog_features = np.array(hog_features).reshape(1, -1)\n",
    "    prediction = model.predict(hog_features)\n",
    "    probability = model.predict_proba(hog_features)[0][prediction[0]]\n",
    "\n",
    "    label = label_encoder.inverse_transform(prediction)[0]\n",
    "\n",
    "    if label in valid_labels and probability >= threshold:\n",
    "        return (int(x * scale), int(y * scale), int((x + window_size[0]) * scale), int((y + window_size[1]) * scale), label, probability)\n",
    "    return None\n",
    "\n",
    "def detect_signs_in_image(image_path, model, label_encoder, threshold=0.65, max_levels=6):\n",
    "    image = io.imread(image_path)\n",
    "    if len(image.shape) > 2:\n",
    "        image = color.rgb2gray(image)\n",
    "\n",
    "    pyramid = pyramid_gaussian(image, downscale=1.5)\n",
    "    detected_boxes = []\n",
    "    detected_labels = []\n",
    "    detected_confidences = []\n",
    "\n",
    "    window_size_1 = (64, 64)\n",
    "    step_size_1 = 48\n",
    "    valid_labels_1 = ['ceder', 'danger', 'interdiction', 'obligation', 'stop']\n",
    "\n",
    "    window_size_2 = (64, 128)\n",
    "    step_size_2 = 48\n",
    "    valid_labels_2 = ['forange', 'frouge', 'fvert']\n",
    "\n",
    "    level_count = 0\n",
    "\n",
    "    for resized in pyramid:\n",
    "        if level_count >= max_levels:\n",
    "            break\n",
    "\n",
    "        scale = image.shape[0] / float(resized.shape[0])\n",
    "\n",
    "        results = Parallel(n_jobs=-1)(delayed(process_window)(\n",
    "            window, x, y, scale, window_size_1, model, label_encoder, valid_labels_1, threshold)\n",
    "            for (x, y, window) in sliding_window(resized, step_size_1, window_size_1)\n",
    "        )\n",
    "        results = [result for result in results if result is not None]\n",
    "        for (x1, y1, x2, y2, label, confidence) in results:\n",
    "            detected_boxes.append((x1, y1, x2, y2))\n",
    "            detected_labels.append(label)\n",
    "            detected_confidences.append(confidence)\n",
    "\n",
    "        results = Parallel(n_jobs=-1)(delayed(process_window)(\n",
    "            window, x, y, scale, window_size_2, model, label_encoder, valid_labels_2, threshold)\n",
    "            for (x, y, window) in sliding_window(resized, step_size_2, window_size_2)\n",
    "        )\n",
    "        results = [result for result in results if result is not None]\n",
    "        for (x1, y1, x2, y2, label, confidence) in results:\n",
    "            detected_boxes.append((x1, y1, x2, y2))\n",
    "            detected_labels.append(label)\n",
    "            detected_confidences.append(confidence)\n",
    "\n",
    "        level_count += 1\n",
    "\n",
    "    indices = non_max_suppression(detected_boxes, detected_confidences, detected_labels, overlap_thresh=0.3)\n",
    "\n",
    "    final_detected_boxes = [detected_boxes[i] for i in indices]\n",
    "    final_detected_labels = [detected_labels[i] for i in indices]\n",
    "    final_detected_confidences = [detected_confidences[i] for i in indices]\n",
    "\n",
    "    # Filtrage pour conserver uniquement un type de feu par image\n",
    "    fire_labels = ['forange', 'frouge', 'fvert']\n",
    "    fire_detections = [(box, label, conf) for box, label, conf in zip(final_detected_boxes, final_detected_labels, final_detected_confidences) if label in fire_labels]\n",
    "    if fire_detections:\n",
    "        best_fire_label = max(fire_detections, key=lambda x: x[2])[1]  # Get the label with the highest confidence\n",
    "        final_detected_boxes = [box for box, label, conf in zip(final_detected_boxes, final_detected_labels, final_detected_confidences) if label not in fire_labels or label == best_fire_label]\n",
    "        final_detected_labels = [label for box, label, conf in zip(final_detected_boxes, final_detected_labels, final_detected_confidences) if label not in fire_labels or label == best_fire_label]\n",
    "        final_detected_confidences = [conf for box, label, conf in zip(final_detected_boxes, final_detected_labels, final_detected_confidences) if label not in fire_labels or label == best_fire_label]\n",
    "\n",
    "    detected_signs = [{\"label\": final_detected_labels[i], \"box\": final_detected_boxes[i], \"confidence\": final_detected_confidences[i]}\n",
    "                      for i in range(len(final_detected_labels))]\n",
    "\n",
    "    return detected_signs\n",
    "\n",
    "def read_real_labels(image_path):\n",
    "    csv_path = image_path.replace('images', 'labels').replace('.jpg', '.csv')\n",
    "    if not os.path.exists(csv_path):\n",
    "        return []\n",
    "\n",
    "    columns = ['x1', 'y1', 'x2', 'y2', 'label']\n",
    "    df = pd.read_csv(csv_path, header=None, names=columns)\n",
    "    real_labels = [{\"box\": (row['x1'], row['y1'], row['x2'], row['y2']), \"label\": row['label']} for index, row in df.iterrows()]\n",
    "    return real_labels\n",
    "\n",
    "# Exemple d'utilisation\n",
    "image_path = 'train/images/0002.jpg'\n",
    "detected_signs = detect_signs_in_image(image_path, clf, label_encoder)\n",
    "real_labels = read_real_labels(image_path)\n",
    "\n",
    "print(\"Detected Signs:\")\n",
    "print(detected_signs)\n",
    "print(\"\\nReal Labels:\")\n",
    "print(real_labels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
